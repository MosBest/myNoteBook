# 2016-7-18
天啊！记得笔记没保存，竟没了

## 小记 
1. 如何用cmd打开ipynb文件
    * 在cmd里，敲 ipython notebook 文件路径 即可
## 当天总结
上午：看完了第2节的课程
2：00--3:00：补看第一节的课程
3：00--8：40：晚上：完成第二节的任务，这个浪费了一些时间，因为读题就读了好半天。
8：40--9：30：这一段时间有些迷茫，浮躁。看了一些大公司的面试题，什么什么的，看了一下又看不下去了。这个坏习惯要改啊。
9：30--之后：看了一些其他的例子文章[名校和非名校最重要差距，悄悄影响着我们的一生](http://mp.weixin.qq.com/s?__biz=MzA5NzIyNjgwMA==&mid=2654418131&idx=1&sn=2b6c27c8682573beea405a7904c9b92e&scene=23&srcid=0716WL8oP0qSCLpSiqwsAh45#rd),有些启发，弄了半天转载，都没有成功，最后把时间用于写今天的总结。

回顾了一下，今天把coursera中华盛顿大学的机器学习系列课程第一课看了两节吧！然后完成了他的作业。 
### 今天的效果不是很好 ###
，因为想和课程一起敲代码的，由于是倒着看的，所以不知道他的数据集和标准库在哪！等找到这些资源后，特别是第一次用这个东西，有些生手，所以耽误了一段时间。

### 知识点回顾
主要就是 getting start Sframe-checkpoint 和 predicting house price 。
1. graphlab包是要收费的，但是通过coursera可以申请免费的非商用版本。
2. 如何用cmd打开ipynb文件
    * 在cmd里，敲 ipython notebook 文件路径 即可
3. graphlab.SFrame（A），A可以是字典，SFrame其实是一种数据结构，可以将字典转化成SFrame这种结构。SFrame处理数据非常方便，开源，同时，得出的表格可视化很好，有点像pandas库，都是比起pandas库，SFrame库可以处理更大量的数据，就好像pandas是将数据加载到内存中运行的，而SFrame可以在硬盘中运行（我猜的）。
   #### 他的表格可视化确实不错
4. 他的具体函数就不具体讲了。不会的可以看ipynb里的具体使用情况。下面仅仅讲一些重要的。
```
     import graphlab
     sf =graphlab.SFrame("asdas.csv")    # 读取数据，并转化为SFrame形式
     sf.show()                           #对每一个特征（列）进行简单的统计
     graphlab.canvas.set_target('ipynb') #让图形输出在ipynb页面上，而不是浏览器或其他程序上面
     sf['age'].show(view='Categorical')  #也是对数据进行统计,以表格的形式呈现,可在halp()上查看其他参数
     sf['full name']=sf['First Name']+' '+sf['Last Name']
                                         #增加特征（列），就是这么简单
     sf['Country']=sf['Country'].apply(transform_contury)
                                         #apply函数的应用，transform_cotury为某一函数，数据集是sf['Cou#ntry']
     
     
     sales.show(view='Scatter Plot',x='sqft_living',y='price') 
                                         #发现好像很区分大小写，比如 'scatter plot','Scatter #plot','scatter' 是完全不同的结果
     train_data,test_data=sales.random_split(0.8,seed=2015)
                                         # seed是种子
     sqft_model=graphlab.linear_regression.create(train_data,target='price',features=['sqft_living'])
                                         # 创建线性模型
     sqft_model.evaluate(test_data)      # 用test——datda数据对模型进行评估。
                                         # 输出结果是一个字典,包含最大误差max error,和rmse,
                                         # rss=sqrt(rmse/N)
     
     import matplotlib.pyplot as plt
     %matplotlib inline                  # 让图输出在ipynb

    plt.plot(test_data['sqft_living'],test_data['price'],'.',
             test_data['sqft_living'],sqft_model.predict(test_data),'-')
    
    sqft_model.get('coefficients')       # coefficients是系数的意思
    print my_model.predict(house1)       # 预测
    filter_sales=sales[(sales['sqft_living']>=2000 ) & (sales['sqft_living']<=4000 )]
                                         # 逻辑过滤一些数据
    filter_sales.num_rows()
        

```


# 2016-7-19 
## 小记
1. 简单的线性分类器（就是所说的打分系统）
    以一个餐厅推荐系统为例。
    写了一大串，后移到自己的csdn上面了。[点击这](http://blog.csdn.net/mosbest/article/details/51953523)
2. 混淆矩阵也可以发展到多维的情况
 ![enter description here][1]

3. 一般情况下，数据量越大，误差就会越小，但是即使数据量趋于无穷大，误差也不会为0，因为偏差一定存在。同时，特征越多，模型越复杂，所需要的数据量也就越多。
明天继续

## 总结
今天无话可说。为什么？我天，coursera真是卡啊！！！无话可说，弄了一天都没弄好。在加上wifi总是突然的连不上，必须重新开机才行。看来是要用ubuntu了，
同时发现，登陆coursera的官网（www.coursera.org）比登陆他的子网慢的多，只要www.coursera.org好了，其他的一般就好了。所以以后尽可能跳过这个步骤。
经过陈政的提醒，以后上coursera时把vpn关了。以后可以通过mooc学院登陆coursera [机器学习基础：案例研究](http://mooc.guokr.com/course/6199/Machine-Learning-Foundations--A-Case-Study-Approach/)
[机器学习基础：案例研究](https://www.coursera.org/learn/ml-foundations/home/welcome)
[机器学习：分类](http://mooc.guokr.com/course/6206/Machine-Learning--Classification/)
千万不要直接登陆coursera的官网
千万不要直接登陆coursera的官网
千万不要直接登陆coursera的官网
我天，现在还没有加载完。
 
 今天算是废了！！！
 
 --------------------------------------------- 
# 2016-7-20
## 小记
今天就一直在折腾ubuntu了，还没有折腾完。现在晚上11：30，前几天熬夜，今天想要早点睡，就记下还没看完的文档
[apt官方文档](http://www.debian.org/doc/manuals/apt-howto/index.zh-cn.html#contents)
[实验楼讲得简单方法](https://www.shiyanlou.com/courses/running)
[ubuntu官网资料](http://wiki.ubuntu.org.cn/%E6%96%B0%E6%89%8B%E5%85%A5%E9%97%A8%E6%8C%87%E5%BC%95)
[buntu桌面入门指南 官网](http://wiki.ubuntu.org.cn/Ubuntu%E6%A1%8C%E9%9D%A2%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97)
[ubuntu详细的安装与配置](http://wenku.it168.com/d_000030466.shtml)
[菜鸟也能玩转Ubuntu：Ubuntu入门到精通](http://wenku.it168.com/wenji/693)(资料超全)


### 感觉学一个东西，最关键的是你能不能找到好的文档。以后会留下这方面的积累。


----------------------------------
# 2016-7-21 星期四
## 小记
简单的总结一下，今天一天到底都干了什么。
今天一天（其实应该加上昨天一天），弄明白了ubuntu下载软件的原理和方法（是不是很好笑，就干了这）。具体的内容写在了博客里了。
[ubuntu学习 之 如何安装软件](http://blog.csdn.net/mosbest/article/details/51985065)
[装完ubuntu以后的基本配置](http://blog.csdn.net/mosbest/article/details/51983574)(还没写完，明天还要继续，脱了两天了，明天是第三天了)

### 发现两点：
 1. 保存在D:,C: 上的东西，在ubuntu系统下打开，可以打开，但是当你编辑的时候，一定要注意了，小书匠会自动的更改文件的名字，然后你做的修改，都保存到了这个文件里面了，对D:,C:,上的内容并没有什么改变。解决方法是，如果你发现 小书匠  自动的更改文件名的话，那么一定要把文件名改回来。包括后缀名也要加上，这就默认为修改原文件了。
 2. 突然发现，xx-net虽然可以翻墙，但是在  “下载东西”  这方面，明显比不上 搜狐浏览器。但是xx-net可以看视频（明明下载东西时，只有20kb,却可以看ubuntu,真是好奇。）这是在windows下测的，不知道ubuntu是不是这样的。
 3. 突然想到，在mooc学院可以看coursera,在 学堂在线 可以看 dex,那是不是可以不用翻墙啊！！明天试试。

----------------------------------------
# 2016-7-22 星期五
今天上午就把昨天未弄完的东西弄完，把博客的内容补全。
下午准备安装一下kazam录屏软件，但是总是报错，弄了一下午，了解的其他的东西到是挺多的，但是还是没弄好，后来基本确定是 软件源的问题。我用netselect-apt更改源时，直接覆盖了原来的sources.list的内容，也就是原来的软件源被我删除了。
晚上，就是看寒小阳关于深度学习的公开课。然后继续查资料，还是没弄明白。

# 2016-7-23 星期六
今天上午，解决了昨天的问题。网上热心肠的人好多啊！！！弄明白UEFI是啥东西。
下午，开始学习机器学习，主要就是把大作业做完。（在csdn上写了篇关于他的博客，笔记也在这上面）程序同该笔记会一同提交到github上面的。
晚上，没有斗志了，准备做中兴人脸识别的比赛，看完之后，自信心完全没了，还是决定提交一些东西，结果就不管了。

发现：在ubuntu用小书匠运行windows10上面的.md文件时，.md文件必须是绝对路径，及时你cd 到该.md文件的路径下，.md也必须要是绝对路径。

# (从今以后，增加明天的任务，要不然总是没有动力，对最终目标没有安排)

## 明天要做的事
1. 上午：学习C++
	对每一节课程，每一个知识点，都在当天笔记“小节”部分写下来，以供当天晚上写总结
2. 下午：  coursera 机器学习：案例研究，
	对每一节课程，每一个知识点，都在当天笔记“小节”部分写下来，以供当天晚上写总结
3. 晚上：林轩田老师 《机器学习技法》
  对每一节课程，每一个知识点，都在当天笔记“小节”部分写下来，以供当天晚上写总结
4. 10:00到宿舍，其他学习的东西就不要看了，写好今天的总结，才是最重要的。第二天早起便是。
5. 填写好明天要完成的表格

--------------------
# 2016-7-24  星期天
## 小节

### 上午
1.  ``` cout << "Size of char : " << sizeof(char) << endl ```;输出为 ``` Size of char : 1 ```
本实例使用了 endl，这将在每一行后插入一个换行符，<< 运算符用于向屏幕传多个值。我们也使用 sizeof() 函数来获取各种数据类型的大小。
2. 
```
typedef 声明
您可以使用 typedef 为一个已有的类型取一个新的名字。下面是使用 typedef 定义一个新类型的语法：
typedef type newname; 
例如，下面的语句会告诉编译器，feet 是 int 的另一个名称：
typedef int feet;
现在，下面的声明是完全合法的，它创建了一个整型变量 distance：
feet distance;
```

3. 枚举类型
建枚举，需要使用关键字 enum。枚举类型的一般形式为：
enum enum-name { list of names } var-list; 

例如，下面的代码定义了一个颜色枚举，变量 c 的类型为 color。最后，c 被赋值为 "blue"。
``` 
enum color { red, green, blue } c;
c = blue;

```
默认情况下，第一个名称的值为 0，第二个名称的值为 1，第三个名称的值为 2，以此类推。但是，您也可以给名称赋予一个特殊的值，只需要添加一个初始值即可。例如，在下面的枚举中，green 的值为 5。
enum color { red, green=5, blue };
在这里，blue 的值为 6，因为默认情况下，每个名称都会比它前面一个名称大 1。


4. 初始化局部变量和全局变量
当局部变量被定义时，系统不会对其初始化，您必须自行对其初始化。定义全局变量时，系统会自动初始化为下列值.正确地初始化变量是一个良好的编程习惯，否则有时候程序可能会产生意想不到的结果。

5. 在程序中，局部变量和全局变量的名称可以相同，但是在函数内，局部变量的值会覆盖全局变量的值。

6. 字符常量
字符常量是括在单引号中。如果常量以 L（仅当大写时）开头，则表示它是一个宽字符常量（例如 L'x'），此时它必须存储在 wchar_t 类型的变量中。否则，它就是一个窄字符常量（例如 'x'），此时它可以存储在 char 类型的简单变量中。

7. 定义常量
在 C++ 中，有两种简单的定义常量的方式：
使用 #define 预处理器。 #define LENGTH 10  
使用 const 关键字。 const int  LENGTH = 10;
请注意，把常量定义为大写字母形式，是一个很好的编程实践。

8. C++ 存储类
存储类定义 C++ 程序中变量/函数的范围（可见性）和生命周期。这些说明符放置在它们所修饰的类型之前。下面列出 C++ 程序中可用的存储类：
auto register static extern mutable [点击这里](http://www.runoob.com/cplusplus/cpp-storage-classes.html)

9. 不要简单的认为 ture就是1，false就是0
10. && 和& 的一个区别就是 一个会发生短路运算，一个不会。最大的区别就是一个是逻辑运算，一个是位运算，所以，&并不能取代&&。 

```
int a=10;
    int b=9;
    printf("%d\n",a&b);
    printf("%d\n",a&&b);

```

结果为 8,1 .

11. 注意：您可以按 Ctrl + C 键终止一个无限循环。

12. c++ 不允许向函数传递一个完整的数组作为参数.

```

函数声明
形式参数是一个已定义大小的数组：
void myFunction(int param[10])
{
}

与
oid myFunction(int *param)
{
}
oid myFunction(int param[])
{
}
是一样的，也就是说那个10是没有用的。他传的还是指针
```
13. C++ 不允许返回一个完整的数组作为函数的参数。
14. 字符串实际上是使用 null 字符 '\0' 终止的一维字符数组。
15. 在变量声明的时候，如果没有确切的地址可以赋值，为指针变量赋一个 NULL 值是一个良好的编程习惯。赋为 NULL 值的指针被称为空指针

16. 可能有一种情况，我们想要让数组存储指向 int 或 char 或其他数据类型的指针。下面是一个指向整数的指针数组的声明：``` int *ptr[MAX]; ```
在这里，把 ptr 声明为一个数组，由 MAX 个整数指针组成。因此，ptr 中的每个元素，都是一个指向 int 值的指针。

17. [c++引用](http://www.runoob.com/cplusplus/cpp-references.html)
18. 通过这些小实例，我们无法区分 cout、cerr 和 clog 的差异，但在编写和执行大型程序时，它们之间的差异就变得非常明显。所以良好的编程实践告诉我们，使用 cerr 流来显示错误消息，而其他的日志消息则使用 clog 流来输出。
### 下午
#### 检索文本问题
比如某一个人在看一本书（称为书A），我们想知道这本书和另一本书（称为书B）的相似度，以此来推荐相似度最高的那本书。。。
提前根据总体的语料库（所有的文档）做一个词典（词向量）
1. bag模型

我们仅仅考虑每一个词在书中出现的次数，而不考虑词在书中的顺序。就好像把书中每一个词都分开，然后装进一个口袋里，摇匀一样。然后统计书A中每一个单词出现的次数，记录在一个向量中(称为向量A)，然后统计书B中每一个单词出现的次数，记录在一个向量中(称为向量B),向量A和向量B的长度一样，也就是说没出现的书在向量的空里面记为0.（注意，向量A，B的长度是根据总体的语料库提前弄好的）
2. 利用bag模型计算 相似度的一种形式，及其缺陷
我们评价书A和书B的相似度，就是看他们出现单词的情况（即单词出现的个数和对应单词出现的个数）是否相同。那其实就是把向量A和向量B做点乘，A*B，值越大，相似度就越大。

缺陷：如果我们把书A和书B都复制成原来的2倍。那么得到的点乘值（即相似度）就是原来的4倍。但就我们来看，其实还是原来的那些书，只是复制一倍而已。所以这种方法其实更加 倾向与文章内容长的书。即文章内容越长，普遍上，相似度就越高。
3. 上面相似度的改进
为了弥补上面提到的缺陷，我们可以对向量A和向量B，都做归一化。即除以他们的范数。A/sqrt(A),B/sqrt(B),z在做一次点乘，就可以了。
4. 但是，以上三点总结出来算法依然有缺陷。
假设一个人喜欢看足球的书，我们肯定是向他推荐足球的书。但是，对于任意一本书（不管是不是足球书），出现最多的单词一定是“a,the, of ,this ,that ,...”。加入有个人喜欢梅西，正在看书A（一本关于梅西的足球文章），又有两本书（书B，书c），书B书关于梅西足球的文章，书C是关科比篮球的文章。对书A，书B，书C分别统计他们的词向量。我们知道，任意一本书“the”可能出现100次，但是即使在梅西的书里，‘梅西’，‘football’出现的次数也不过10次。那么计算出来的值，‘the’的影响程度远远高于‘fotball’。也就是说，我们真正想要的关键字（‘football’，‘梅西’）其实早已经被‘the’，‘a’这样不重要的字给淹没了。（终于明白为什么我的垃圾邮箱分类器的错误率那么高了，）
所以，要想提高算法的精确度，我们就要提高关键字（important words)的权重，降低普通字的权重。所谓的关键字，就是那种 在书A经常出现，但是在所有的文档(语料库)里罕见的词。即关键字就是局部常见，全局罕见的词。（比如'梅西'）
下面就介绍TF-IDF 来解决这种问题。

5. TF-IDF

先计算语料库（所有文档）的IDF（Inverse document frequency ）
	对于词典向量里的每一个空，用公式 $$ log\frac{Alldocs}{1+docUsingWords}  $$ 填写，Alldocs是指语料库所有的文档，docUsingWords是指某一个词在所有文档中出现的个数。比如我们职工有50篇文章，'梅西'在50篇文章出现的次数为3，在词典向量‘梅西’那一空格中，应该填的值为 $$ log\frac{50}{1+3} $$ 。'the'在50篇文章出现的次数为49，在词典向量‘the’那一空格中，应该填的值为 $$ log\frac{50}{1+49} $$ =0 。这样语料库越是普通的单词，他在IDF里的值就越小，语料库越是普通的单词，他在IDF里的值就越大。我们得到语料库的IDF向量。

再计算书A的TF（Term frequency ）
	其实就是原来的向量A，这里记为A_TF,A_TF就是书A的词向量（要进行归一化）。
然后计算书A的最终词向量
	就是A=A_TF * IDF.(向量的点乘)

![如图](http://img.blog.csdn.net/20160724170901507)

然后计算书B的TF（Term frequency ）
	其实就是原来的向量B，这里记为B_TF,B_TF就是书B的词向量（要进行归一化）。

然后计算书B的最终词向量
	就是B=B_TF * IDF.(向量的点乘)

最后A，B的相似度
	A * B

6. 利用TF-IDF来度量两本书的相似度。我们前面说过，我们的总共有50篇文档。那么我们计算每篇文档与书A的相似度，取相似度最高的那篇文档，把他推荐给那个人，这就是最近邻算法。由此演变出来的K-紧邻算法，就是取出最近的k个文档。



### 晚上
学习了支持向量机，笔记写在了自己的博客上了[svm系列之最大分隔超平面](http://blog.csdn.net/MosBest/article/details/52017312)

## 当天总结
这次总节是7月25号，星期一写的。因为没想到写那个博客用了那么多的时间。所以就不占用当天过多的时间，简单的说一下就是了。
上午学的是C++的基础,记下了一些常见，容易忽略的问题。
下午学的的coursera上关于 检索文本 ，推荐书籍  的问题。主要是介绍了最终 相似度  确定方法TF-IDF法。
晚上是支持向量机的基层部分。写了一些博客


## 明天要做的事
1. 上午：c++
	对每一节课程，每一个知识点，都在当天笔记“小节”部分写下来，以供当天晚上写总结
2. 下午： coursera 机器学习：案例研究，
	对每一节课程，每一个知识点，都在当天笔记“小节”部分写下来，以供当天晚上写总结
3. 晚上：林轩田老师 《机器学习基石》（决定从头开始）
  对每一节课程，每一个知识点，都在当天笔记“小节”部分写下来，以供当天晚上写总结
4. 10:00到宿舍，其他学习的东西就不要看了，写好今天的总结，才是最重要的。第二天早起便是。
5. 填写好明天要完成的表格


  [1]: ./images/%E6%97%A0%E6%A0%87%E9%A2%98.png "无标题.png"
