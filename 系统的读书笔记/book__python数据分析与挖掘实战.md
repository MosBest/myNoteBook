[TOC]
# 常见指令
## 其他常见命令
1. np.linspace(0,30,50) 
    #表示0到30，分50份

2. scipy.interpolate()
功能：包含了大量的一维，或者 高维 的 插值函数

3. D.unique() 或者 np.unique(D)

![这里写图片描述](http://img.blog.csdn.net/20160916102557626)

4. 随机打乱数据
```python
from random import shuffle
data=data.as_matrix() # 不知道这一句要不要
shuffle(data)
```
5. 绘制ROC曲线
代码仅提供思路，并不一定对
```python
from sklearn.metrics import roc_curve
predict=model.predict(y).reshape(len(y))
fpr,tpr,thresholds=roc_curve(y,predict,pos_label=1)
plt.plot(fpr,tpr,linewidth=2,lael=u'ROC曲线')
plt.xlabel('...')
plt.ylabel('...')
plt.xlim(0,1)#边界
plt.ylim(0,1)#边界
plt.legend(loc=4)#图例
plt.show()
```
6. 

## 统计命令
1. data.describe()
2. corr() 计算相关系数
    * D.corr(method='pearson'),D为DataFrame,返回的是相关系数矩阵
    * S1.corr(S2,method='pearson'),S1,S2均为Series
3. cov() 协方差矩阵
    * D.cov()
    * S1.cov(S2)
![这里写图片描述](http://img.blog.csdn.net/20160915211508259)
![这里写图片描述](http://img.blog.csdn.net/20160915211615448)
![这里写图片描述](http://img.blog.csdn.net/20160915211734278)

# 绘图
定量数据 绘制 频率分布直方图
定性数据 绘制 饼图 或者 条形图
作图完成后，一般通过plt.show()来显示作图结果。
1. plot()
    * plt.plot(x,y,S)
    其中S表示输入的其他参数。比如颜色，样式等等。eg: plt.plot(x,y,'bo-') 这里nan'se
    
    * D.plot(kind='box',S)
    默认以index为横坐标，每一列的数据为纵坐标自动作图。
    S的意思同上面，kind指定作图类型。支持line(线),bar(条形),barh,hist(直方图),box(箱型图),kde(密度图),area,pie(饼图)等。
2. plt.pie(size)
    size是一个列表，记录各个扇形的比例
    pie还有其他的参数
plt.axis('equal') # 显示为圆（避免比例压缩为椭圆）

3. plt.hist(x,n)
    其中x为待绘制直方图的一维数组，n可以为整数，表示均匀分为n组，也可以是列表，列表各个数字为分组的边界点。

4. D.boxplot() 或者 D.plot(kind='box')
5. D.plot(logx=True) / D.plot(logy=True)
    绘制x或者y的对数图形
6. D.plot(xerr= ) 或者 D.plot(yerr= )
    xerr表示在x轴方向画出误差棒图
    yerr表示在y轴方向画出误差棒图

# 基础篇
## 异常值分析
### 观测出异常值
在很多情况下，要先分析异常值出现的可能原因，再判断异常值是否应该舍弃，如果是正确值，可以直接在具有异常的数据集上进行挖掘建模。

1. 看数据是否超过合理范围
比如人的年龄，如果有的数据给出的人的年龄为200岁，那么他就是一个异常值
2. 3$ \sigma $原则  
要求数据服从 正态分布。
如果数据服从正态分布，那么异常值被定义为一组测定值中与平均值的偏差超过3倍的标准差的值，即|x-$\mu$|>3*$\sigma$的区域

3. 箱型图
优点：1. 没有对数据做任何限定性要求，（如服从某种特定的分布形式）
      2. 用四分位点鲁棒性好

但是不一定准确，还要结合具体业务

异常值被定义为：小于$Q_L-1.5IQR$或者大于 $Q_u+1.5IQR$
$Q_L$表示下四分位点，$Q_u$表示上四分位点，IQR称为四分位点间距，即$Q_u - Q_l$

### 处理异常值
![这里写图片描述](http://img.blog.csdn.net/20160916090933311)

直接删除，可能会丢掉一些有用信息

视为缺失值处理的好处是可以利用现有变量的信息，对异常值（缺失值）进行填补。

##  缺失值处理
在对数据插值之前先对数据进行异常值检测。

![这里写图片描述](http://img.blog.csdn.net/20160916100824197) 拉格朗日插值法：就是利用前n个值得到一个包含有n的自变量的回归方程，然后用 这个回归方程来拟合要预测的缺失值。所以预测的结果很依赖n的选取。

牛顿插值法
不是很懂他的表达式。

## 数据变换
### 简单的数据变换
比如：平方，开方，取对数，差分运算
![这里写图片描述](http://img.blog.csdn.net/20160916093000668) 
简单的函数变换常用于将不具有正态分布的数据变换成具有正态分布的数据
对于时间序列，简单的对数运算或者差分运算就可以将非平稳序列变换为平稳序列。

### 规范化
用的最多的是标准差标准化。
因为最小--最大规范化在某个数值很大时，规范化后的各个值会接近于0.

## 连续属性离散化
1. 等宽法
缺点：在于它对离群值比较敏感，倾向于不均匀地把属性值分布到各个区间。有些区间包含许多数据，而另外一些区间的数据极少，这样会严重损坏建立的决策模型。

2. 等频法
虽然避免了上述问题，却可能将相同的数据值分到不同的区间以满足每个区间中固定的数据个数。

所以在一般情况下，还是用等宽法，只是在运用等宽法划分之前，可以先对数据进行简单的变化（比如进行log运算），缩减数据与离群值的距离。或者进行离群值检验，删除掉离群点。

3. 基于聚类的方法

## 相关系数
1. pearson 相关系数
要求连续变量服从正态分布，且之判定是否为 线性相关的
|r|=0表示不存在线性相关。r>0表示存在正相关，r<0表示存在负相关。

2. Spearman 秩相关系数
不服从正态分布，分类或等级变量之间的关联性 可采用此方法。
在正态分布假定下，Spearman秩相关系数与Pearson相关系数在效率上是等价的。而对于连续测量数据，更适合用Pearson相关系数来进行分析。

3. 判定系数
就是相关系数的平方，$r^2$


## 其他常识
1. 均值：最主要的问题是对极端值很敏感。如果数据中存在极端值或者数据是偏态分布，那么均值就不能很好的度量数据的集中趋势。为了消除少数极端值的影响，可以使用 ==截断均值== (去掉高,低极端值之后的平均值) 或者 ==中位值== 来度量数据的集中趋势。
2. 逻辑回归本质上还是一种线性模型，无法处理非线性或者共线性的情况。选出来的特征，系数越大，只能表明其与结果具有比较强的==线性==相关性。
3. sklearn提供了RFE包，可以用于特征消除，还提供了RFECV,可以通过交叉验证来对特征进行排序。
4. 目前神经网络中流行的防止过拟合的方法是随机地让部分神经网络节点休眠。


# 时间序列模型
模型预测时间越长，误差越大。
先预处理（即平稳性检验和纯随机性检验），根据检验结果可以将序列分为不同的类型，对不同的类型的序列采取不同的分析方法。
纯随机序列 ： 即 白噪声序列，如果序列在进行完全无序的随机波动，可以终止对该序列的分析。因为白噪声没有信息可以提取。
平稳非白噪声序列 ： 其 均值和方差 是常数。 ARMA模型是最常见的平稳序列拟合模型

非平稳序列：  非平稳序列一定不是白噪声序列。其均值和方差不稳定。
处理方法：将其转化为平稳序列（取对数，差分等等），这样就可以应用有关平稳时间序列的分析方法。
如果其经过差分运算后具有平稳性，则该序列为差分平稳序列，他就可以用ARIMA模型进行分析。

## 首先进行平稳性检验
方法：
1. 时序图（带有主观性）
画出序列的时序图。如果时序图显示该序列始终在第一个常数附近随机波动，而且波动的范围有界。
但是如果有明显的趋势性，或者周期性，那他==通常==不是平稳序列。
2. 自相关图检验（带有主观性）
平稳序列==通常==只有近期的序列对现时值的影响比较明显，间隔越远的过去值对现时值的影响越小。
即随着（期数）k的增加，平稳序列的自相关系数$p_k$会比较快的衰减趋于零，并在零附近随机波动。而非平稳序列的自相关系数衰减的速度比较慢。
3. 单位根检验（最常用）
序列如果存在单位根，那么就是非平稳时间序列。

## 再进行纯随机性检验
## 平稳时间序列分析
对于该情况，常见的三大模型： AR(p)模型,MA(q)模型,ARMA(p,q)模型
其实AR(p)模型和MA(q)模型是ARMA(p,q)模型当q=0或p=0时候的特例。

建模步骤：、
具体见书124页

1. 先通过上面的 平稳性检验和蠢随机性检验，确定这是平稳时间序列分析。
2. 计算序列 ACF(自相关系数) 和 PACF(偏自相关系数)。用于确定使用上面三个中的那个模型。同时确定模型的系数p,q.依据是（见书P124页表）
其实就是看 ACF和PACF哪个拖尾，那个截尾，如果是截尾，那么是几阶截尾。

## 非平稳时间序列
ARIMA模型
许多非平稳序列差分后会显示出平稳序列的性质。这时称他为 差分平稳序列。对差分平稳序列可以使用ARMA.
ARIMA模型其实就是差分运算与ARMA模型的组合。
最终要求，残差为白噪声序列。

具体步骤，见书P125页图5-18

## 代码实现

```python
#-*- coding: utf-8 -*-
#arima时序模型

import pandas as pd

#参数初始化
discfile = '../data/arima_data.xls'
forecastnum = 5

#读取数据，指定日期列为指标，Pandas自动将“日期”列识别为Datetime格式
data = pd.read_excel(discfile, index_col = u'日期')

#时序图
import matplotlib.pyplot as plt
plt.rcParams['font.sans-serif'] = ['SimHei'] #用来正常显示中文标签
plt.rcParams['axes.unicode_minus'] = False #用来正常显示负号
data.plot()
plt.show()

#自相关图
from statsmodels.graphics.tsaplots import plot_acf
plot_acf(data).show()

#平稳性检测
from statsmodels.tsa.stattools import adfuller as ADF
print(u'原始序列的ADF检验结果为：', ADF(data[u'销量']))
#返回值依次为adf、pvalue、usedlag、nobs、critical values、icbest、regresults、resstore

#差分后的结果
D_data = data.diff().dropna()
D_data.columns = [u'销量差分']
D_data.plot() #时序图
plt.show()
plot_acf(D_data).show() #自相关图
from statsmodels.graphics.tsaplots import plot_pacf
plot_pacf(D_data).show() #偏自相关图
print(u'差分序列的ADF检验结果为：', ADF(D_data[u'销量差分'])) #平稳性检测

#白噪声检验
from statsmodels.stats.diagnostic import acorr_ljungbox
print(u'差分序列的白噪声检验结果为：', acorr_ljungbox(D_data, lags=1)) #返回统计量和p值

from statsmodels.tsa.arima_model import ARIMA

#定阶
pmax = int(len(D_data)/10) #一般阶数不超过length/10
qmax = int(len(D_data)/10) #一般阶数不超过length/10
bic_matrix = [] #bic矩阵
for p in range(pmax+1):
  tmp = []
  for q in range(qmax+1):
    try: #存在部分报错，所以用try来跳过报错。
      tmp.append(ARIMA(data, (p,1,q)).fit().bic)
    except:
      tmp.append(None)
  bic_matrix.append(tmp)

bic_matrix = pd.DataFrame(bic_matrix) #从中可以找出最小值

p,q = bic_matrix.stack().idxmin() #先用stack展平，然后用idxmin找出最小值位置。
print(u'BIC最小的p值和q值为：%s、%s' %(p,q)) 
model = ARIMA(data, (p,1,q)).fit() #建立ARIMA(0, 1, 1)模型
model.summary2() #给出一份模型报告
model.forecast(5) #作为期5天的预测，返回预测结果、标准误差、置信区间。

```

## 关于时间序列模型要使用的函数

见书P132-P133页

主要包括平稳性检验，白噪声检验，是否差分，AIC和BIC指标值，模型定阶，最后再做预测。

# 实战篇
## 1. 电力窃漏电用户自动识别
处理过程：
1. 数据探索
    分布分析:画出不同用户窃漏电用户的直方图，发现非居民类别不存在窃漏电情况
    周期性分析：发现正常用户用电情况呈周期性，而窃漏电用户有下降趋势
2. 数据预处理
    1. 数据清洗
        根据前面的数据探索，由于 非居民用电类别 不存在漏电情况，所以将其删除
        节假日与工作日不同，会明显偏低，所以过滤节假日的用电情况。
    2. 缺失值处理-----用拉格朗日填充法
        代码见，P153页
    3. 特征变换（亮点）
        原始数据虽然在一定程度上面能够反映某些规律，但是特征不明显，需要重新构建
        1. 根据前面的数据探索2，发现普遍情况下，窃漏电用户有下降趋势。那么我求出每一点前5天后5天共11天数据构成的直线斜率，再计算这11天当天比前一天用电趋势为递减的天数，作为这一点的特征。这样，值越大，他是窃漏电的风险就越大
        2. 改进的线损率方案。
        线损率就是电路在线路上面的损耗。即（线路供电量-用户用电量）/线路供电量。如果存在窃漏电现象，那么线路供电量会增加，但是用户用电量不变，导致线损率增加。但是由于用户用电都是存在波动的，所以单纯的以线损率上升作为特征，误差会很大。我们想到的方法是，把当前与前5天之间的线损率平均值作为$V_1$，当天与后5天之间的线损率平均值作为$v_2$,如果$V_1$比$V_2$增加（$V_2$比$V_1$减小）超过1%，表明有窃漏电现象。结果为0或者1。
        3.告警类指标
        考虑到告警可能存在报错，漏报情况，那么就把终端报警的次数的总和作为特征。
        
    4. 进一步（亮点）
    最后，观测结果。针对误判的用户，研究其在窃漏电期间的用电行为，优化模型的特征，提高识别的精度。
    
3. 